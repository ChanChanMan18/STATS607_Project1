#' Perform 2-fold cross-validation IMPROPERLY; in particular, perform
#' preprocessing step BEFORE data splitting according to the main
#' example of Moscovich and Rosset (2022). The covariates with the K
#' largest empirical variance are selected for prediction prior to 
#' data splitting.
#' 
#' Input:
#' data_list - Results of simulation as generated by generate_sample
#' p - Number of predictors before preprocessing performed
#' K - Number of predictors to be selected according to largest variance
#' sample_size - number of simulated data points
#' 
#' Output:
#' MSE_Mean_Incorrect - Average of all MSEs across folds 

source('src/feature_select_var.R')

improper_cv_2fold <- function(data_list, p, K = 10, sample_size, seed) {
  
  y <- data_list$y
  X <- data_list$X
  
  # Selecting K variables with highest empirical variance BEFORE cv
  sel <- feature_select_var(X, K)  
  Xk <- sel$X_K_highest_var
  
  # Make two roughly equal folds, set seed for reproducibility
  set.seed(seed)
  idx_all <- sample.int(sample_size)
  folds <- split(idx_all, rep(1:2, length.out = sample_size))
  
  mse_fold <- numeric(2)
  
  # Train on one fold's complement, test on that fold
  for (f in 1:2) {
    test_idx  <- folds[[f]]
    train_idx <- setdiff(seq_len(sample_size), test_idx)
    
    training_data <- as.data.frame(Xk[train_idx, , drop = FALSE])
    testing_data  <- as.data.frame(Xk[test_idx,  , drop = FALSE])
    
    # Ensure identical predictor names in train/test
    colnames(training_data) <- colnames(testing_data) <- paste0("X", seq_len(K))
    
    y_train <- y[train_idx]
    y_test  <- y[test_idx]
    
    all_data_training <- cbind(training_data, output_values_train = y_train)
    
    # Fit (no intercept)
    fit <- lm(output_values_train ~ . + 0, data = all_data_training)
    
    # Predict on the test fold
    y_hat <- predict(fit, newdata = testing_data)
    
    # Fold MSE
    mse_fold[f] <- mean((y_test - y_hat)^2)
  }
  
  # Compute mean across folds
  MSE_Mean_Incorrect <- mean(mse_fold)
  return(MSE_Mean_Incorrect)
}